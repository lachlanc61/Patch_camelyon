{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explore\n"
     ]
    }
   ],
   "source": [
    "%load core.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load core.py\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import Sequential \n",
    "\n",
    "import src.utils as utils\n",
    "\n",
    "\"\"\"\n",
    "Practice project - histology\n",
    "\n",
    "\"\"\"\n",
    "#-----------------------------------\n",
    "#Vars\n",
    "#-----------------------------------\n",
    "\n",
    "CONFIG_FILE='config.yaml'\n",
    "\n",
    "#-----------------------------------\n",
    "#INITIALISE\n",
    "#-----------------------------------\n",
    "\n",
    "config=utils.readcfg(CONFIG_FILE)\n",
    "\n",
    "wdirname=config['wdirname']\n",
    "odirname=config['odirname']\n",
    "batchlen=config['batchlen']\n",
    "\n",
    "#if we're not training, hide GPU to avoid it going OOM when viewing layer outputs\n",
    "#   sure there must be a way to do this more cleanly\n",
    "if not config['DOTRAIN']:\n",
    "    tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "print(f'python version: {sys.version}')\n",
    "print(f'tensorflow version: {tf.__version__}')\n",
    "\n",
    "gpu_available = (len(tf.config.list_physical_devices('GPU')) > 0)\n",
    "print(f'GPU: {gpu_available}')\n",
    "\n",
    "spath, wdir, odir, checkpoint_path, checkpoint_dir = utils.initialise(config)\n",
    "\n",
    "#-----------------------------------\n",
    "#MAIN START\n",
    "#-----------------------------------\n",
    "\n",
    "print(\"---------------\")\n",
    "data, info = tfds.load('patch_camelyon', with_info = True, as_supervised = True)\n",
    "\n",
    "dtrain = data['train']\n",
    "dvalidation = data['validation']\n",
    "dtest = data['test']\n",
    "\n",
    "#normalise all to range(0,1) - speeds up ML calc\n",
    "# tfds.map performs (function) on each element of the array\n",
    "dtrain = dtrain.map(utils.normalise)\n",
    "dvalidation = dvalidation.map(utils.normalise)\n",
    "dtest = dtest.map(utils.normalise)\n",
    "\n",
    "#shuffle the training data to use a different set each time\n",
    "dtrain=dtrain.shuffle(config['buffer'])\n",
    "\n",
    "#get a sub-batch for training\n",
    "dtrain = dtrain.batch(batchlen) \n",
    "dvalidation = dvalidation.batch(batchlen) \n",
    "dtest = dtest.batch(batchlen) \n",
    "\n",
    "#extract tensor elements\n",
    "#   iter converts to iterable object\n",
    "#   next extracts element from each\n",
    "#   comes as (image, label) tuple\n",
    "\n",
    "timg, tlabels = next(iter(dtrain))\n",
    "vimg, vlabels = next(iter(dvalidation))\n",
    "testimg, testlabels  = next(iter(dtest))\n",
    "\n",
    "#check shapes for both\n",
    "#should correspond to batch size\n",
    "print(\"labelshape:\",vlabels.shape)\n",
    "print(\"imgshape:\",timg.shape)\n",
    "print(\"batch size:\",batchlen)\n",
    "if config['PREPLOT']:\n",
    "  #plot 12 random images as RGB, including label as true/false \n",
    "  fig, ax = plt.subplots(2,6, figsize=(12,5))\n",
    "  fig.tight_layout(pad=0.1)\n",
    "\n",
    "  for i,ax in enumerate(ax.flat):\n",
    "      rand = np.random.randint(batchlen)    \n",
    "      ax.imshow(timg[rand,:,:,:])\n",
    "      ax.set_title(bool(tlabels.numpy()[rand]))\n",
    "      ax.set_axis_off()\n",
    "\n",
    "  plt.show()\n",
    "  exit()\n",
    "\n",
    "#we are overfitting pretty heavily, try regularisation\n",
    "l2reg=tf.keras.regularizers.L2(config['lamda'])\n",
    "#kernel_regularizer=l2reg\n",
    "  #not great, slow and not a big improvement, leave it out for now\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "MODEL HERE\n",
    "\n",
    "  convolution layer (Nfilters,Npx,...)\n",
    "    basically a set of N filters acting on a window of MxM px slid across whole image\n",
    "      output shape x,y,Nfilters\n",
    "  \n",
    "  max pooling layer (Npx)\n",
    "    sliding Npx x Npx window\n",
    "    outputs max value within window\n",
    "      effectively downsamples image retaining max\n",
    "      https://www.youtube.com/watch?v=ZjM_XQa5s6s\n",
    "\n",
    "  use relu function instead of signmoid for all but output layer\n",
    "  basically max(0,val)\n",
    "  = passthrough if above 0\n",
    "    more responsive across entire range compared to sigmoid\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#Initialise basic TF model\n",
    "\"\"\"\n",
    "Simpler, faster model for testing, still gets 0.7-0.75 most of the time\n",
    "\"\"\"\n",
    "model = Sequential(\n",
    "    [\n",
    "        keras.layers.Conv2D(64,3, padding='same', activation='relu', input_shape=[96, 96, 3], name=\"block1_conv1\"),\n",
    "        keras.layers.MaxPooling2D(2, name=\"block1_pool\"),\n",
    "        keras.layers.Conv2D(32,3, padding='same', activation='relu', name=\"block2_conv1\"),\n",
    "        keras.layers.MaxPooling2D(2, name=\"block2_pool\"),\n",
    "        keras.layers.Conv2D(16,3, padding='same', activation='relu', name=\"block3_conv1\"),\n",
    "        keras.layers.MaxPooling2D(2, name=\"block3_pool\"),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(256, activation='relu', name=\"dense1\"),\n",
    "        keras.layers.Dense(128, activation='relu', name=\"dense2\"),\n",
    "        keras.layers.Dense(56, activation='relu', name=\"dense3\"),\n",
    "        keras.layers.Dense(12, activation='relu', name=\"dense4\"), \n",
    "        keras.layers.Dense(1, activation='sigmoid', name=\"predictions\") \n",
    "    ], name = \"my_model\" \n",
    ")   \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "gets ~0.75 fairly consistently - slow, large\n",
    "model = Sequential(\n",
    "    [\n",
    "        keras.layers.Conv2D(256,3, padding='same', activation='relu', input_shape=[96, 96, 3]),\n",
    "        keras.layers.MaxPooling2D(2),\n",
    "        keras.layers.Conv2D(1024,3, padding='same', activation='relu'),\n",
    "        keras.layers.MaxPooling2D(2),\n",
    "        keras.layers.Conv2D(256,3, padding='same', activation='relu'),\n",
    "        keras.layers.MaxPooling2D(2),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(256, activation='relu'),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dense(56, activation='relu'),\n",
    "        keras.layers.Dense(12, activation='relu'), \n",
    "        keras.layers.Dense(1, activation='sigmoid') \n",
    "    ], name = \"my_model\" \n",
    ")   \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#view model summary\n",
    "model.summary()\n",
    "\n",
    "#compile the model\n",
    "#   acc = track accuracy vs train/val sets\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.0005),\n",
    "    metrics=['acc'],\n",
    ")\n",
    "\n",
    "\n",
    "#Callbacks\n",
    "#   (special utilities executed during training)\n",
    "# https://blog.paperspace.com/tensorflow-callbacks/\n",
    "\n",
    "#stop refinement early if val stops improving\n",
    "#https://towardsdatascience.com/a-practical-introduction-to-early-stopping-in-machine-learning-550ac88bc8fd\n",
    "stopcond=keras.callbacks.EarlyStopping(monitor='val_loss', patience=config['stoplim'])\n",
    "\n",
    "\n",
    "#save model during training every 5 batches\n",
    "# save best model only based on val_loss\n",
    "\n",
    "#ok i am stumped on saving best model\n",
    "#   get warning \"Can save best model only with val_acc available, skipping\"\n",
    "#   looks like val_acc not making it into model.metrics somehow\n",
    "\n",
    "#BUT val_loss works for early stoping callback. both are available in history\n",
    "#I guess just save every 5 for now.... creates a pile of checkpoints, \n",
    "#       will miss very best one unless save every epoch\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                               #  save_best_only=True,\n",
    "                                                 monitor='val_acc',\n",
    "                                                 verbose=1,\n",
    "                                                 save_freq=1*config['batch_size'])\n",
    "\n",
    "\n",
    "#TRAIN/LOAD\n",
    "\n",
    "#if training, do it\n",
    "#else load model from checkpoint variable (manually set)\n",
    "\n",
    "if config['DOTRAIN']:\n",
    "  #run the fit, saving params to fitlog \n",
    "  #   epochs = N. cycles\n",
    "  #   validation data is tested each epoch\n",
    "  fitlog = model.fit(\n",
    "      timg,tlabels,\n",
    "      epochs=config['nepochs'],\n",
    "      validation_data = (vimg, vlabels),\n",
    "      validation_freq = 1,\n",
    "      callbacks=[stopcond,cp_callback],\n",
    "      batch_size=config['batch_size'],\n",
    "      verbose=1\n",
    "  )\n",
    "\n",
    "  print(model.metrics_names)\n",
    "\n",
    "  #demonstrating val_acc is present\n",
    "  for key in fitlog.history:\n",
    "    print(key)\n",
    "\n",
    "  #extract metrics for plotting\n",
    "  tacc = fitlog.history['acc']\n",
    "  tloss = fitlog.history['loss']\n",
    "  vacc = fitlog.history['val_acc']\n",
    "  vloss = fitlog.history['val_loss']\n",
    "\n",
    "\n",
    "  #plot fit progress against train and validation data\n",
    "  if config['POSTPLOT']:\n",
    "    fig, ax = plt.subplots(1,2, figsize=(12,6))\n",
    "    fig.tight_layout(pad=2)\n",
    "\n",
    "    epochs = range(1, len(tacc) + 1)\n",
    "    ax[0].plot(epochs, tacc, 'r', label='Training accuracy')\n",
    "    ax[0].plot(epochs, vacc, 'b', label='Validation accuracy')\n",
    "    ax[0].set_title('Accuracy')\n",
    "    ax[0].legend()\n",
    "\n",
    "    ax[1].plot(epochs, tloss, 'r', label='Training loss')\n",
    "    ax[1].plot(epochs, vloss, 'b', label='Validation loss')\n",
    "    ax[1].set_title('Loss')\n",
    "    ax[1].legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "else: #if not training\n",
    "  #load from checkpoint variable\n",
    "  model.load_weights(config['cptoload'])\n",
    "  tloss, tacc = model.evaluate(timg, tlabels, verbose=2)\n",
    "  vloss, vacc = model.evaluate(vimg, vlabels, verbose=2)\n",
    "\n",
    "  print(\"MODEL LOAD SUCCESSFUL\\n\"\n",
    "  f'checkpoint: {config[\"cptoload\"]}\\n'\n",
    "  f'------------------------\\n'\n",
    "  f'train loss: {tloss:>9.3f}\\n'\n",
    "  f'train acc : {tacc:>9.3f}\\n'\n",
    "  f'------------------------\\n'\n",
    "  f'val loss  : {vloss:>9.3f}\\n'\n",
    "  f'val acc   : {vacc:>9.3f}\\n')\n",
    "  f'------------------------\\n'\n",
    "\n",
    "#  calc and print test result\n",
    "#   prefer not to see this till later\n",
    "if False:\n",
    "  eval = model.evaluate(testimg, testlabels)\n",
    "  print(\"EVAL\\n\"\n",
    "  f'test loss: {eval[0]}\\n'\n",
    "  f'test acc:  {eval[1]}\\n')\n",
    "\n",
    "\n",
    "if config['LAYEROUTPLOT']:\n",
    "  \"\"\"\n",
    "  https://machinelearningmastery.com/how-to-visualize-filters-and-feature-maps-in-convolutional-neural-networks/\n",
    "  save outputs of first 16 filters \n",
    "    for all conv/pool layers\n",
    "    for one random image\n",
    "  \"\"\"\n",
    "\n",
    "  #extract layer outputs\n",
    "  extractor = keras.Model(inputs=model.inputs,\n",
    "                          outputs=[layer.output for layer in model.layers])\n",
    "\n",
    "  #pick a random image\n",
    "  rand = np.random.randint(batchlen)   \n",
    "  img=timg[rand,:,:,:]\n",
    "\n",
    "  # expand dimensions so that it represents a single 'sample'\n",
    "  eimg = np.expand_dims(img, axis=0)\n",
    "  print(eimg.shape)\n",
    "\n",
    "  #extract feature maps from expanded image\n",
    "  feature_maps = extractor.predict(eimg)\n",
    "\n",
    "  #initialise the plots (using mosaic)\n",
    "  fig, ax = plt.subplot_mosaic(\"AABCD;AAEFG;HIJKL;MNOPQ\", figsize=(16,12))\n",
    "  fig.tight_layout(pad=1)\n",
    "\n",
    "  #plot original as RGB, including label as true/false \n",
    "  ax[\"A\"].imshow(img)\n",
    "  ax[\"A\"].set_title(bool(tlabels.numpy()[rand]))\n",
    "  ax[\"A\"].set_axis_off()\n",
    "\n",
    "  #iterate through layers, plotting first 16 filter outputs for each\n",
    "  #save to new file\n",
    "  #leave original image in place for all\n",
    "\n",
    "  j=0 #layer index\n",
    "  for layer in model.layers:\n",
    "    # skip if not convolutional/pool layer\n",
    "    if ('conv' not in layer.name) and ('pool' not in layer.name):\n",
    "      j+=1    #still increment layer index\n",
    "      continue\n",
    "\n",
    "    #iterate through first 16 filters\n",
    "    #   should probably randomise this in future\n",
    "    i=0   #filter index\n",
    "\n",
    "    #iterate through mosaic dict for axes\n",
    "    for key in ax:\n",
    "      #if looking at original image axis, print the layer and skip\n",
    "      if key == \"A\":\n",
    "        print(layer.name)\n",
    "        print(j)\n",
    "      else:\n",
    "        #plot the feature map\n",
    "        # indexing/slicing is weird here, don't fully understand these objects\n",
    "        #   [layer][image=0][x,y,filter]\n",
    "        #   not sure why it has this format\n",
    "        ax[key].imshow(feature_maps[j][0][:,:,i])\n",
    "        ax[key].set_axis_off()\n",
    "        i+=1\n",
    "\n",
    "    #save the figure for each layer\n",
    "    plt.savefig(os.path.join(odir, f'{layer.name}.png'), dpi=300)\n",
    "    j+=1\n",
    "\n",
    "print(\"CLEAN EXIT\")\n",
    "exit()\n",
    "\n",
    "\"\"\"\n",
    "performance log\n",
    "\n",
    "3 layers 256 128, batch 512 - 0.6 vacc\n",
    "4 layers 256 128, batch 512 - 0.63 vacc\n",
    "4 layers 256 128 batch 8k  - ~0.65 vacc - v slow\n",
    "\n",
    "4+1 batch 512               -   ~0.7 vacc\n",
    "  1 conv2D 32,3             - seems unstable, vacc varying 0.65-0.75\n",
    "  4 dense 256,128,56,12 \n",
    "    4250 ms/step on CPU\n",
    "    ~27 ms/step on GPU\n",
    "\n",
    "try L2_regularisation on all layers\n",
    "  - much slower (1.2 sec), still 0.7-0.75 vacc\n",
    "  - maybe more stable but seems not worth\n",
    "\n",
    "    Ok here's an example\n",
    "    https://medium.com/analytics-vidhya/deep-learning-tutorial-patch-camelyon-data-set-d0da9034550e\n",
    "      6 conv2D layers + 6 \"maxpool\" layers - what is this?\n",
    "      3 dense layers\n",
    "      gets ~0.75, 150ms/step\n",
    "\n",
    "try adding this maxpool layer  - 0.72 vacc, more stable?\n",
    "  faster - 17ms/step\n",
    "\n",
    "\n",
    "up to three conv+maxpool layers\n",
    "  256 1024 256 \n",
    "  touches 0.77 but very slow to train\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "resources\n",
    "\n",
    "really good explanation of maxpooling here\n",
    "https://www.youtube.com/watch?v=ZjM_XQa5s6s\n",
    "\n",
    "also nice CNN overview\n",
    "https://www.youtube.com/watch?v=YRhxdVk_sIs\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 64-bit ('venv_patchcam')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "77574a2eb40d68b0ab187ac81eb83b9d7d84aa6a26feab2dbd48e8a77088fb95"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
