{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explore\n"
     ]
    }
   ],
   "source": [
    "%load core.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-05 22:19:46.577562: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-10-05 22:19:47.935412: I tensorflow/c/logging.cc:34] Successfully opened dynamic library libdirectml.0de2b4431c6572ee74152a7ee0cd3fb1534e4a95.so\n",
      "2022-10-05 22:19:47.935563: I tensorflow/c/logging.cc:34] Successfully opened dynamic library libdxcore.so\n",
      "2022-10-05 22:19:47.946400: I tensorflow/c/logging.cc:34] Successfully opened dynamic library libd3d12.so\n",
      "2022-10-05 22:19:49.634824: I tensorflow/c/logging.cc:34] DirectML device enumeration: found 1 compatible adapters.\n",
      "/home/lachlan/.pyenv/versions/venv_patchcam/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script path: /home/lachlan/CODEBASE/Patch_camelyon\n",
      "working path: /home/lachlan/CODEBASE/Patch_camelyon/train\n",
      "output path: /home/lachlan/CODEBASE/Patch_camelyon/out\n",
      "cp: /home/lachlan/CODEBASE/Patch_camelyon/train/cp-{epoch:04d}.ckpt\n",
      "cp: /home/lachlan/CODEBASE/Patch_camelyon/train\n",
      "---------------\n",
      "python version: 3.7.13 (default, Sep  4 2022, 13:19:50) \n",
      "[GCC 9.4.0]\n",
      "tensorflow version: 2.9.2\n",
      "GPU: True\n",
      "---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-05 22:19:50.408228: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-05 22:19:50.409328: I tensorflow/c/logging.cc:34] DirectML: creating device on adapter 0 (NVIDIA GeForce RTX 2070)\n",
      "2022-10-05 22:19:51.082836: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-10-05 22:19:51.082881: W tensorflow/core/common_runtime/pluggable_device/pluggable_device_bfc_allocator.cc:28] Overriding allow_growth setting because force_memory_growth was requested by the device.\n",
      "2022-10-05 22:19:51.082902: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6827 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labelshape: (256,)\n",
      "imgshape: (256, 96, 96, 3)\n",
      "batch size: 256\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "preplot() missing 2 required positional arguments: 'timg' and 'tlabels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_943/2099653139.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PREPLOT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m#we are overfitting pretty heavily, try regularisation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: preplot() missing 2 required positional arguments: 'timg' and 'tlabels'"
     ]
    }
   ],
   "source": [
    "# %load core.py\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import Sequential \n",
    "\n",
    "import src.utils as utils\n",
    "import src.tfmodel as tfmodel\n",
    "import src.vis as vis\n",
    "\n",
    "\"\"\"\n",
    "Practice project - histology\n",
    "\n",
    "\"\"\"\n",
    "#-----------------------------------\n",
    "#Vars\n",
    "#-----------------------------------\n",
    "\n",
    "CONFIG_FILE='config.yaml'\n",
    "DSETNAME='patch_camelyon'\n",
    "#-----------------------------------\n",
    "#INITIALISE\n",
    "#-----------------------------------\n",
    "\n",
    "config=utils.readcfg(CONFIG_FILE)\n",
    "\n",
    "wdirname=config['wdirname']\n",
    "odirname=config['odirname']\n",
    "batchlen=config['batchlen']\n",
    "\n",
    "spath, wdir, odir, checkpoint_path, checkpoint_dir = utils.initialise(config)\n",
    "\n",
    "#-----------------------------------\n",
    "#MAIN START\n",
    "#-----------------------------------\n",
    "\n",
    "dtrain, dvalidation, dtest, dsinfo = utils.datainit(config, DSETNAME)\n",
    "\n",
    "timg, tlabels, vimg, vlabels, testimg, testlabels = utils.tensorinit(dtrain, dvalidation, dtest)\n",
    "\n",
    "#check shapes for both\n",
    "#should correspond to batch size\n",
    "print(\"labelshape:\",vlabels.shape)\n",
    "print(\"imgshape:\",timg.shape)\n",
    "print(\"batch size:\",batchlen)\n",
    "\n",
    "if config['PREPLOT']:\n",
    "    vis.preplot(config, timg, tlabels)\n",
    "\n",
    "#we are overfitting pretty heavily, try regularisation\n",
    "l2reg=tf.keras.regularizers.L2(config['lamda'])\n",
    "#kernel_regularizer=l2reg\n",
    "  #not great, slow and not a big improvement, leave it out for now\n",
    "\n",
    "\n",
    "model = tfmodel.build(config)\n",
    "\n",
    "model, fitlog = tfmodel.train(model, timg, tlabels, vimg, vlabels, config, checkpoint_path)\n",
    "\n",
    "vis.layerplot(config, model, timg, tlabels, odir)\n",
    "\n",
    "print(\"CLEAN EXIT\")\n",
    "exit()\n",
    "\n",
    "\"\"\"\n",
    "performance log\n",
    "\n",
    "3 layers 256 128, batch 512 - 0.6 vacc\n",
    "4 layers 256 128, batch 512 - 0.63 vacc\n",
    "4 layers 256 128 batch 8k  - ~0.65 vacc - v slow\n",
    "\n",
    "4+1 batch 512               -   ~0.7 vacc\n",
    "  1 conv2D 32,3             - seems unstable, vacc varying 0.65-0.75\n",
    "  4 dense 256,128,56,12 \n",
    "    4250 ms/step on CPU\n",
    "    ~27 ms/step on GPU\n",
    "\n",
    "try L2_regularisation on all layers\n",
    "  - much slower (1.2 sec), still 0.7-0.75 vacc\n",
    "  - maybe more stable but seems not worth\n",
    "\n",
    "    Ok here's an example\n",
    "    https://medium.com/analytics-vidhya/deep-learning-tutorial-patch-camelyon-data-set-d0da9034550e\n",
    "      6 conv2D layers + 6 \"maxpool\" layers - what is this?\n",
    "      3 dense layers\n",
    "      gets ~0.75, 150ms/step\n",
    "\n",
    "try adding this maxpool layer  - 0.72 vacc, more stable?\n",
    "  faster - 17ms/step\n",
    "\n",
    "\n",
    "up to three conv+maxpool layers\n",
    "  256 1024 256 \n",
    "  touches 0.77 but very slow to train\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "resources\n",
    "\n",
    "really good explanation of maxpooling here\n",
    "https://www.youtube.com/watch?v=ZjM_XQa5s6s\n",
    "\n",
    "also nice CNN overview\n",
    "https://www.youtube.com/watch?v=YRhxdVk_sIs\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 64-bit ('venv_patchcam')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "77574a2eb40d68b0ab187ac81eb83b9d7d84aa6a26feab2dbd48e8a77088fb95"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
